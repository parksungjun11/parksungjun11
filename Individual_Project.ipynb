{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Individual Project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN/S1xaHaYwPkLWh1buWzDC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parksungjun11/parksungjun11/blob/main/Individual_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5IeOxGxohTT"
      },
      "source": [
        "**반드시 런타임 유형을 GPU로 변경하고 실행해주세요!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5k2MldEHMTD"
      },
      "source": [
        "1. 한글 폰트를 설치하고 런타임 다시 시작을 눌러주세요 이 과정이 끝나면 데이터 업로드부분으로 바로 넘어가시면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dyqHnUPHJdM"
      },
      "source": [
        "# 한글 폰트 설치하기 (꼭! 설치가 완료되면 [런타임 다시 시작]을 누르고 다시 실행하기)\n",
        "!apt install fonts-nanum -y\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# 한글 폰트 설정하기\n",
        "font_path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font1 = fm.FontProperties(fname=font_path, size=10)\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "matplotlib.font_manager._rebuild()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGCHb_muHUhq"
      },
      "source": [
        "#코드를 실행하는데 필요한 라이브러리\n",
        "import os\n",
        "import zipfile\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import matplotlib.image as mpimg\n",
        "import shutil\n",
        "from google.colab import files \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ5do7BcHSX5"
      },
      "source": [
        "2. 이미 한번 시행하여 사용할 데이터셋을 만들었기 때문에 데이터셋을 만들고 각자 강아지별로 이미지를 다운받아와서 또 다시 데이터 셋을 안만드셔도 됩니다. (이러한 코드를 사용하여 데이터를 만들었다를 보는것이 목적이기 때문입니다.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRIDYbbpHRqK"
      },
      "source": [
        "#bing 이미지를 다운받기 위한 코드 \n",
        "!git clone https://github.com/ndb796/bing_image_downloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLUqpSpaHYsS"
      },
      "source": [
        "#수집한 bing 이미지들을 넣을 데이터셋 만들기\n",
        "from bing_image_downloader.bing_image_downloader import downloader\n",
        "directorylist = [\n",
        "    './dog_dataset/training/',\n",
        "    './dog_dataset/testing/',\n",
        "]\n",
        "\n",
        "# 초기 디렉토리 만들기\n",
        "for directory in directorylist:\n",
        "    if not os.path.isdir(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "# 수집한 이미지를 학습 데이터와 평가 데이터로 구분하는 함수\n",
        "def data_split(dog_name, training_count):\n",
        "    # 학습 및 평가 데이터셋 디렉토리 만들기\n",
        "    for directory in directorylist:\n",
        "        if not os.path.isdir(directory + '/' + dog_name):\n",
        "            os.makedirs(directory + '/' + dog_name)\n",
        "    # 학습 및 평가 데이터셋 준비하기\n",
        "    count = 0\n",
        "    for file_name in os.listdir(dog_name):\n",
        "        if count < training_count:\n",
        "            print(f'[Train Dataset] {file_name}')\n",
        "            shutil.move(dog_name + '/' + file_name, './dog_dataset/training/' + dog_name + '/' + file_name)\n",
        "        else:\n",
        "            print(f'[Test Dataset] {file_name}')\n",
        "            shutil.move(dog_name + '/' + file_name, './dog_dataset/testing/' + dog_name + '/' + file_name)\n",
        "        count += 1\n",
        "    shutil.rmtree(dog_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RszW0cPeHb-B"
      },
      "source": [
        "3. 2번에서 언급했던 것처럼 bing에서 비숑, 말티즈, 푸들 ,포메라니안, 시츄의 이미지를 가져옵니다.(코드를 채점하실 때는 이 부분은 참고만 해주시면 될거같습니다.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7_sIXnsHaMC"
      },
      "source": [
        "#bing에서 비숑의 이미지를 검색하여 약 300여개의 이미지를 가져오고 8:2의 비율로 random하게 train과 test에 저장\n",
        "dog_name = '비숑'\n",
        "downloader.download(dog_name, limit=300,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
        "data_split(dog_name, 230)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqXAXzUwHeEa"
      },
      "source": [
        "#bing에서 말티즈의 이미지를 검색하여 약 300여개의 이미지를 가져오고 8:2의 비율로 random하게 train과 test에 저장\n",
        "dog_name = '말티즈'\n",
        "downloader.download(dog_name, limit=300,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
        "data_split(dog_name, 230)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6s-DfN0CHfpa"
      },
      "source": [
        "#bing에서 푸들의 이미지를 검색하여 약 300여개의 이미지를 가져오고 8:2의 비율로 random하게 train과 test에 저장\n",
        "dog_name = '푸들'\n",
        "downloader.download(dog_name, limit=300,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
        "data_split(dog_name, 230)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--cahk8-HhVC"
      },
      "source": [
        "#bing에서 포메라니안의 이미지를 검색하여 약 300여개의 이미지를 가져오고 8:2의 비율로 random하게 train과 test에 저장\n",
        "dog_name = '포메라니안'\n",
        "downloader.download(dog_name, limit=300,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
        "data_split(dog_name, 230)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWnNg5_nHiyS"
      },
      "source": [
        "#bing에서 시츄의 이미지를 검색하여 약 300여개의 이미지를 가져오고 8:2의 비율로 random하게 train과 test에 저장\n",
        "dog_name = '시츄'\n",
        "downloader.download(dog_name, limit=300,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
        "data_split(dog_name, 230)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-5yZhLeHlBq"
      },
      "source": [
        "#colab에 있는 데이터셋을 zip으로 압축 (매번 코드를 실행할때 마다 데이터셋이 바뀌고 데이터 수집에 시간이 걸리므로 좀 더 시간단축)\n",
        "dog_zip = zipfile.ZipFile('/content/dog_dataset.zip', 'w') # 압축 후 저장 위치\n",
        "for folder, subfolders, files in os.walk('/content/dog_dataset'): # 압축 할 폴더\n",
        "    for file in files:\n",
        "        if file.endswith('.jpg'): # 압축할 파일 확장자\n",
        "            dog_zip.write(os.path.join(folder, file), os.path.relpath(os.path.join(folder,file), '/content/dog_dataset/'), \n",
        "                          compress_type = zipfile.ZIP_DEFLATED)\n",
        "dog_zip.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqFu-yBcHqXR"
      },
      "source": [
        "4. 한글 폰트 코드가 완료되면 colab에 데이터셋 업로드하는 부분으로 바로 넘어오시면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw4Y9tV_HnDk"
      },
      "source": [
        "#google colab에 데이터셋 업로드 (대략 데이터 크기가 커서 30분정도 소요)\n",
        "from google.colab import files \n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('업로드 파일 \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUCv0PLeHo0D"
      },
      "source": [
        "#업로드한 데이터셋 압축 풀기\n",
        "!mkdir -p ./dog_dataset\n",
        "!unzip dog_dataset.zip -d dog_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTskOa3BHwFJ"
      },
      "source": [
        "5. 압축을 푼 데이터셋트의 기본정보 확인 및 train에 있는 각각 클래스 (비숑, 말티즈, 푸들, 포메라니안, 시츄)의 이미지를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mMyebt7Ht4U"
      },
      "source": [
        "#업로드한 데이터셋의 기본정보를 얻기 위해 실시\n",
        "# 기본 경로\n",
        "base_dir = '/content/dog_dataset'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'training')\n",
        "test_dir = os.path.join(base_dir, 'testing')\n",
        "\n",
        "# 훈련에 사용되는 고양이/개 이미지 경로\n",
        "train_말티즈_dir = os.path.join(train_dir, '말티즈')\n",
        "train_비숑_dir = os.path.join(train_dir, '비숑')\n",
        "train_시츄_dir = os.path.join(train_dir, '시츄')\n",
        "train_포메라니안_dir = os.path.join(train_dir, '포메라니안')\n",
        "train_푸들_dir = os.path.join(train_dir, '푸들')\n",
        "print(train_말티즈_dir)\n",
        "print(train_비숑_dir)\n",
        "print(train_시츄_dir)\n",
        "print(train_포메라니안_dir)\n",
        "print(train_푸들_dir)\n",
        "\n",
        "# 테스트에 사용되는 고양이/개 이미지 경로\n",
        "test_말티즈_dir = os.path.join(test_dir, '말티즈')\n",
        "test_비숑_dir = os.path.join(test_dir, '비숑')\n",
        "test_시츄_dir = os.path.join(test_dir, '시츄')\n",
        "test_포메라니안_dir = os.path.join(test_dir, '포메라니안')\n",
        "test_푸들_dir = os.path.join(test_dir, '푸들')\n",
        "\n",
        "print(test_말티즈_dir)\n",
        "print(test_비숑_dir)\n",
        "print(test_시츄_dir)\n",
        "print(test_포메라니안_dir)\n",
        "print(test_푸들_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG3gFvAAHyBD"
      },
      "source": [
        "#위에 처럼 각각 클래스별로 train,test에 어느정도의 이미지가 있는지 확인\n",
        "train_말티즈_fname = os.listdir( train_말티즈_dir )\n",
        "train_비숑_fname = os.listdir( train_비숑_dir )\n",
        "train_시츄_fname = os.listdir( train_시츄_dir )\n",
        "train_포메라니안_fname = os.listdir( train_포메라니안_dir )\n",
        "train_푸들_fname = os.listdir( train_푸들_dir )\n",
        "\n",
        "print(train_말티즈_fname[:7])\n",
        "print(train_비숑_fname[:7])\n",
        "print(train_시츄_fname[:7])\n",
        "print(train_포메라니안_fname[:7])\n",
        "print(train_푸들_fname[:7])\n",
        "\n",
        "\n",
        "print('train dataset에 속한 말티즈 이미지 개수 :', len(os.listdir(train_말티즈_dir)), '개')\n",
        "print('train dataset에 속한 비숑 이미지 개수 :', len(os.listdir(train_비숑_dir)), '개')\n",
        "print('train dataset에 속한 시츄 이미지 개수 :', len(os.listdir(train_시츄_dir)), '개')\n",
        "print('train dataset에 속한 포메라니안 이미지 개수 :', len(os.listdir(train_포메라니안_dir)), '개')\n",
        "print('train dataset에 속한 푸들 이미지 개수 :', len(os.listdir(train_푸들_dir)), '개')\n",
        "print('test dataset에 속한 말티즈 이미지 개수 :', len(os.listdir(test_말티즈_dir)), '개')\n",
        "print('test dataset에 속한 비숑 이미지 개수 :', len(os.listdir(test_비숑_dir)), '개')\n",
        "print('test dataset에 속한 시츄 이미지 개수 :', len(os.listdir(test_시츄_dir)), '개')\n",
        "print('test dataset에 속한 포메라니안 이미지 개수 :', len(os.listdir(test_포메라니안_dir)), '개')\n",
        "print('test dataset에 속한 푸들 이미지 개수 :', len(os.listdir(test_푸들_dir)), '개')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8tQO3qtH0RK"
      },
      "source": [
        "#말티즈 train dataset에 있는 클래스들의 이미지를 불러옴(5개)\n",
        "%matplotlib inline\n",
        "nrows, ncols = 100,100\n",
        "pic_index = 0\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "pic_index+=100\n",
        "\n",
        "next_말티즈_pix = [os.path.join(train_말티즈_dir, fname)\n",
        "                for fname in train_말티즈_fname[ pic_index-5:pic_index]]\n",
        "                \n",
        "for i, img_path in enumerate(next_말티즈_pix ):\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off')\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF3ZJma2H1y6"
      },
      "source": [
        "#비숑 train dataset에 있는 클래스들의 이미지를 불러옴(5개)\n",
        "%matplotlib inline\n",
        "nrows, ncols = 100,100\n",
        "pic_index = 0\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "pic_index+=100\n",
        "\n",
        "next_비숑_pix = [os.path.join(train_비숑_dir, fname)\n",
        "                for fname in train_비숑_fname[ pic_index-5:pic_index]]\n",
        "                \n",
        "for i, img_path in enumerate(next_비숑_pix ):\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off')\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt0h9qjFH3ZS"
      },
      "source": [
        "#시츄 train dataset에 있는 클래스들의 이미지를 불러옴(5개)\n",
        "%matplotlib inline\n",
        "nrows, ncols = 100,100\n",
        "pic_index = 0\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "pic_index+=65\n",
        "\n",
        "next_시츄_pix = [os.path.join(train_시츄_dir, fname)\n",
        "                for fname in train_시츄_fname[ pic_index-5:pic_index]]\n",
        "                \n",
        "for i, img_path in enumerate(next_시츄_pix ):\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off')\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jSaInkmH5J7"
      },
      "source": [
        "#포메라니안 train dataset에 있는 클래스들의 이미지를 불러옴(5개)\n",
        "%matplotlib inline\n",
        "nrows, ncols = 100,100\n",
        "pic_index = 0\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "pic_index+=60\n",
        "\n",
        "next_포메라니안_pix = [os.path.join(train_포메라니안_dir, fname)\n",
        "                for fname in train_포메라니안_fname[ pic_index-5:pic_index]]\n",
        "                \n",
        "for i, img_path in enumerate(next_포메라니안_pix ):\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off')\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH-sulMMH6vT"
      },
      "source": [
        "#푸들 train dataset에 있는 클래스들의 이미지를 불러옴(5개)\n",
        "%matplotlib inline\n",
        "nrows, ncols = 100,100\n",
        "pic_index = 0\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "pic_index+=12\n",
        "\n",
        "next_푸들_pix = [os.path.join(train_푸들_dir, fname)\n",
        "                for fname in train_푸들_fname[ pic_index-5:pic_index]]\n",
        "                \n",
        "for i, img_path in enumerate(next_푸들_pix ):\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off')\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxx8BRCGH-Dh"
      },
      "source": [
        "6. 이미지 정규화를 통해 격자 이미지로 시각화 및 후에 모델의 학습을 위한 준비를 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9uPyyGCH8Mq"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device 객체\n",
        "\n",
        "# 데이터셋을 불러올 때 사용할 변형(transformation) 객체 정의\n",
        "transforms_train = transforms.Compose([\n",
        "    transforms.Resize((225, 225)),\n",
        "    transforms.RandomHorizontalFlip(), # 데이터 증진(augmentation)\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 정규화(normalization)\n",
        "])\n",
        "\n",
        "transforms_test = transforms.Compose([\n",
        "    transforms.Resize((225, 225)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_datasets = datasets.ImageFolder(os.path.join(base_dir, 'training'), transforms_train)\n",
        "test_datasets = datasets.ImageFolder(os.path.join(base_dir, 'testing'), transforms_test)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_datasets, batch_size=4, shuffle=True, num_workers=2)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_datasets, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "print('학습 데이터셋 크기:', len(train_datasets))\n",
        "print('테스트 데이터셋 크기:', len(test_datasets))\n",
        "\n",
        "class_names = train_datasets.classes\n",
        "print('클래스:', class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ9bmPceIADi"
      },
      "source": [
        "def image_show(input, title):\n",
        "    # torch.Tensor를 numpy 객체로 변환\n",
        "    input = input.numpy().transpose((1, 2, 0))\n",
        "    # 이미지 정규화 해제하기\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    input = std * input + mean\n",
        "    input = np.clip(input, 0, 1)\n",
        "    # 이미지 출력\n",
        "    plt.imshow(input)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 학습 데이터를 배치 단위로 불러오기\n",
        "iterator = iter(train_dataloader)\n",
        "\n",
        "# 현재 배치를 이용해 격자 형태의 이미지를 만들어 시각화\n",
        "inputs, classes = next(iterator)\n",
        "outputs = torchvision.utils.make_grid(inputs)\n",
        "image_show(outputs, title=[class_names[i] for i in classes])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVevBQ4AIDfx"
      },
      "source": [
        "7. resnet34를 이용하여 학습모델을 만들고 학습모델을 바탕으로 train에 있는 이미지를 학습시킵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XucibBDLIB7K"
      },
      "source": [
        "#resnet34을 이용하여 학습할 데이터 모델을 만듬\n",
        "data_model = models.resnet34(pretrained=True)\n",
        "num_features = data_model.fc.in_features\n",
        "# 전이 학습(transfer learning): 모델의 출력 뉴런 수를 3개로 교체하여 마지막 레이어 다시 학습\n",
        "data_model.fc = nn.Linear(num_features, 5)\n",
        "data_model = data_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(data_model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnPG6NSyIFQy"
      },
      "source": [
        "#데이터 모델의 층의 구성\n",
        "data_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Or8JvMaIGmq"
      },
      "source": [
        "#만든 모델을 학습하기 전 테스트 데이터에 대해 예측실시\n",
        "data_model.eval()\n",
        "start_time = time.time()\n",
        "\n",
        "with torch.no_grad():\n",
        "    running2_loss = 0.\n",
        "    running2_corrects = 0\n",
        "\n",
        "    for input, label in test_dataloader:\n",
        "        input = input.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        output = data_model(input)\n",
        "        _, preds = torch.max(output, 1)\n",
        "        loss = criterion(output, label)\n",
        "\n",
        "        running2_loss += loss.item() * input.size(0)\n",
        "        running2_corrects += torch.sum(preds == label.data)\n",
        "\n",
        "        # 한 배치의 첫 번째 이미지에 대하여 결과 시각화\n",
        "        print(f'[예측 결과: {class_names[preds[0]]}] (실제 정답: {class_names[label.data[0]]})')\n",
        "        image_show(input.cpu().data[0], title='예측 결과: ' + class_names[preds[0]])\n",
        "\n",
        "    epoch2_loss = running2_loss / len(test_datasets)\n",
        "    epoch2_acc = running2_corrects / len(test_datasets) * 100.\n",
        "    print('[Test Phase] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch2_loss, epoch2_acc, time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkWQezlPIK4a"
      },
      "source": [
        "#모델을 학습시키기 -> 총 10번 실시 \n",
        "num_epoch = 15\n",
        "data_model.train()\n",
        "start_time = time.time()\n",
        "a,b= [],[]\n",
        "# 전체 반복(epoch) 수 만큼 반복하며\n",
        "for epoch in range(num_epoch):\n",
        "    train_running_loss = 0.\n",
        "    train_running_corrects = 0\n",
        "    # 배치 단위로 학습 데이터 불러오기\n",
        "    for input, label in train_dataloader:\n",
        "        input = input.to(device)\n",
        "        label = label.to(device)\n",
        "        # 모델에 입력(forward)하고 결과 계산\n",
        "        optimizer.zero_grad()\n",
        "        output = data_model(input)\n",
        "        _, preds = torch.max(output, 1)\n",
        "        loss = criterion(output, label)\n",
        "        # 역전파를 통해 기울기(gradient) 계산 및 학습 진행\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_running_loss += loss.item() * input.size(0)\n",
        "        train_running_corrects += torch.sum(preds == label.data)\n",
        "    train_epoch_loss = train_running_loss / len(train_datasets)\n",
        "    train_epoch_acc = train_running_corrects / len(train_datasets) * 100.\n",
        "    a.append(train_epoch_loss*100)\n",
        "    b.append(train_epoch_acc)\n",
        "    # 학습 과정 중에 결과 출력\n",
        "    print('#{} train_Loss(손실): {:.4f} train_Acc(정확도): {:.4f}% Time: {:.4f}초'.format(epoch, train_epoch_loss, train_epoch_acc,time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7p5wAS3IMkK"
      },
      "source": [
        "# 그래프 시각화를 위한 %값을 float으로 실수형으로 변경함\n",
        "for i in range(15):\n",
        "  b[i] = format(b[i])\n",
        "  b[i] = float(b[i])\n",
        "print(b)  \n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v9XsHFBIN3a"
      },
      "source": [
        "#train과 test의 정확도와 손실을 한눈에 볼 수 있게 그래프로 시각화\n",
        "epoch_num = []\n",
        "for i in range(len(a)):\n",
        "  epoch_num.append(i)\n",
        "plt.plot(epoch_num, b, 'b', label='Training accuracy')\n",
        "plt.plot(epoch_num, a, 'b',color= 'red', label='Training loss')\n",
        "plt.title('Training')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npbQkf3KIRHZ"
      },
      "source": [
        "8. 학습한 모델을 바탕으로 test dataset에 있는 이미지를 정확히 분류하는지 예측합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0Y7yyuLIPIS"
      },
      "source": [
        "#학습한 모델을 바탕으로 test 데이터 셋을 다시 예측함\n",
        "data_model.eval()\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "    running2_loss = 0.\n",
        "    running2_corrects = 0\n",
        "    for input, label in test_dataloader:\n",
        "        input = input.to(device)\n",
        "        label = label.to(device)\n",
        "        output = data_model(input)\n",
        "        _, preds = torch.max(output, 1)\n",
        "        loss = criterion(output, label)\n",
        "        running2_loss += loss.item() * input.size(0)\n",
        "        running2_corrects += torch.sum(preds == label.data)\n",
        "        # 한 배치의 첫 번째 이미지에 대하여 결과 시각화\n",
        "        print(f'[예측 결과: {class_names[preds[0]]}] (실제 정답: {class_names[label.data[0]]})')\n",
        "        image_show(input.cpu().data[0], title='예측 결과: ' + class_names[preds[0]])\n",
        "    epoch2_loss = running2_loss / len(test_datasets)\n",
        "    epoch2_acc = running2_corrects / len(test_datasets) * 100.\n",
        "    print('[Test 단계] test_loss(손실): {:.4f} test_acc(정확도): {:.4f}% Time: {:.4f}s'.format(epoch2_loss, epoch2_acc, time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9VXD8kSIUV5"
      },
      "source": [
        "9. dataset에 없는 이미지를 바탕으로 이미지를 정확히 분류하는지 확인해봅니다.    (웹페이지에서 각각 클래스 이름을 입력했을 때 나오는 이미지를 사용)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9Zxy7hKIUDg"
      },
      "source": [
        "#말티즈의 이미지를 가져옴\n",
        "!wget https://images.mypetlife.co.kr/content/uploads/2019/12/09152009/dog-1123026_1920.jpg -O test_image.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOsHnRE4Iefj"
      },
      "source": [
        "#말티즈 이미지 예측\n",
        "image = Image.open('test_image.jpg')\n",
        "image = transforms_test(image).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = data_model(image)\n",
        "    _, preds = torch.max(output, 1)\n",
        "    image_show(image.cpu().data[0], title='예측 결과: ' + class_names[preds[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrb830hnIfsb"
      },
      "source": [
        "#비숑 이미지\n",
        "!wget https://images.mypetlife.co.kr/content/uploads/2017/12/09160633/Dognews-1.jpg -O test_image1.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dFaiM6OIg8L"
      },
      "source": [
        "#비숑 이미지 예측\n",
        "image = Image.open('test_image1.jpg')\n",
        "image = transforms_test(image).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = data_model(image)\n",
        "    _, preds = torch.max(output, 1)\n",
        "    image_show(image.cpu().data[0], title='예측 결과: ' + class_names[preds[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Kd6558EIiHb"
      },
      "source": [
        "#시츄 이미지\n",
        "!wget https://images.mypetlife.co.kr/content/uploads/2020/06/09150430/samuel-girven-0AG5oa9oGBQ-unsplash-scaled-e1593587400633.jpg -O test_image2.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFSZSZ6PIj50"
      },
      "source": [
        "#시츄 이미지 예측\n",
        "image = Image.open('test_image2.jpg')\n",
        "image = transforms_test(image).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = data_model(image)\n",
        "    _, preds = torch.max(output, 1)\n",
        "    image_show(image.cpu().data[0], title='예측 결과: ' + class_names[preds[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW35P3nBIlkj"
      },
      "source": [
        "#포메라니안 이미지\n",
        "!wget https://images.mypetlife.co.kr/content/uploads/2018/05/09160725/pexels-photo-732456.jpeg -O test_image3.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YokT354bIm2z"
      },
      "source": [
        "#포메라니안 이미지 예측\n",
        "image = Image.open('test_image3.jpg')\n",
        "image = transforms_test(image).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = data_model(image)\n",
        "    _, preds = torch.max(output, 1)\n",
        "    image_show(image.cpu().data[0], title='예측 결과: ' + class_names[preds[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nqp-hESPIoYk"
      },
      "source": [
        "#푸들 이미지\n",
        "!wget https://images.mypetlife.co.kr/content/uploads/2020/05/09150723/standard-poodle-4311162_1280-1024x682.jpg -O test_image4.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnoYjl1EIpwz"
      },
      "source": [
        "#푸들 이미지 예측\n",
        "image = Image.open('test_image4.jpg')\n",
        "image = transforms_test(image).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = data_model(image)\n",
        "    _, preds = torch.max(output, 1)\n",
        "    image_show(image.cpu().data[0], title='예측 결과: ' + class_names[preds[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqaV6aSXIuCz"
      },
      "source": [
        "10. 마지막으로 키우는 강아지의 이미지 분류를 예측합니다. (이 이미지는 압축파일의 bichon_image폴더를 다운받으셔서 하시면 됩니다.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH8WPUbxIrHb"
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO6WNyJ-IwQ7"
      },
      "source": [
        "#실제 키우는 강아지 이미지를 가져오기\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, jsonify, request\n",
        "# 이미지를 읽어 결과를 반환하는 함수\n",
        "def get_pred(image_bytes):\n",
        "    image = Image.open(io.BytesIO(image_bytes))\n",
        "    image = transforms_test(image).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = data_model(image)\n",
        "        _, preds = torch.max(output, 1)\n",
        "        image_show(image.cpu().data[0], title='예측 결과: ' + class_names[preds[0]])\n",
        "    return class_names[preds[0]]\n",
        "application = Flask(__name__)\n",
        "@application.route('/', methods=['POST'])\n",
        "def image_predict():\n",
        "    if request.method == 'POST':\n",
        "        # 이미지 바이트 데이터 받아오기\n",
        "        file = request.files['file']\n",
        "        image_bytes = file.read()\n",
        "\n",
        "        # 분류 결과 확인 및 클라이언트에게 결과 반환\n",
        "        class_name = get_pred(image_bytes=image_bytes)\n",
        "        print(\"결과:\", {'이름': class_name})\n",
        "        return jsonify({'이름': class_name})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbGarquJIygr"
      },
      "source": [
        "run_with_ngrok(application)\n",
        "application.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdmfarzJI6TJ"
      },
      "source": [
        "아래의 주석은 10번 부분을 수행하실때 참고하서셔 하시된 될거같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8COgF1uI39j"
      },
      "source": [
        "'''\n",
        "1. 명령 프롬프트 열기 -> windows키 + r 키를 동시에 누르면 열림 -> C:\\Users\\user > 라고 되어있음\n",
        "2. 현재 사진이 있는 경로를 C:\\Users\\user> 옆에 복사하여 적어줌\n",
        "   ex)현재 사진이 있는 경로가 \"C:\\Users\\user\\Pictures\\test2\"라면, \n",
        "   C:\\Users\\user> cd \"C:\\Users\\user\\Pictures\\test2\"라고 입력을 해줌(반드시 경로 앞에 cd도 같이 입력!!!)\n",
        "   성공적으로 입력이 완료되면 \"C:\\Users\\user\\Pictures\\test2\" > 라는 표시로 바뀌게 됨\n",
        "4.\"C:\\Users\\user\\Pictures\\test2\"> 옆에 curl -X POST -F file=@bis1.jpg http://63dd-34-71-213-192.ngrok.io 라고 입력을 함 (여기서 bis1.jpg는 사진의 이름에다가 jpg를 붙여준 것)\n",
        "  http://63dd-34-71-213-192.ngrok.io는 run_with_ngrok(application) application.run()코드를 실행시켜줬을 때 두번째 running on의 주소를 복사해 주면 됨 (반드시 두번째 주소!!)\n",
        "5. C:\\Users\\user\\Pictures\\test2 > curl -X POST -F file=@bis3.jpg http://63dd-34-71-213-192.ngrok.io 이런식으로 입력이 완료되면 colab에 사진이 업로드 되고 사진의 예측결과를 확인하면 끝!!\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-11VyBr9I4Zz"
      },
      "source": [
        "\"\"\"\n",
        "아래는 명령 프롬프트를 열었을 때 제가 작성해본것 입니다.\n",
        "1. C:\\Users\\user> (이는 명령 프롬프트를 처음 열었을 때 나오는 코드로 이 코드 옆에 현재 컴퓨터에 이미지가 저장된 경로를 복사해서 붙여넣어주면 됩니다.  이를 올바르게 수행하면 2번처럼 될 것입니다.)\n",
        "2. C:\\Users\\user> cd \"C:\\Users\\user\\Pictures\\test2\" (저는 user의 pictures의 test2 폴더에 사진이 있어 이렇게 경로를 복사해주었고 교수님께서는 이 폴더가 저장된 곳의 경로를 불러오시면 됩니다.)\n",
        "\n",
        "3. \"C:\\Users\\user\\Pictures\\test2\" > curl -X POST -F file=@bichon1.jpg http://63dd-34-71-213-192.ngrok.io (이미지가 있는 경로에서 이제 curl -X POST -F file=@bichon1.jpg http://63dd-34-71-213-192.ngrok.io를 입력해주시면 되는데 \n",
        "                                                                                                        여기서는 실행할 때 마다 http://63dd-34-71-213-192.ngrok.io의 경로가 바뀌기에 이것만 running on의 두번째 주소를 복사해주시고  \n",
        "                                                                                                        curl -X POST -F file=@bichon1.jpg 이부분은 그대로 복사해주시면 됩니다. )\n",
        "4. \"C:\\Users\\user\\Pictures\\test2\" > curl -X POST -F file=@bichon2.jpg http://63dd-34-71-213-192.ngrok.io  (3번과 마찬기지로 runnin on의 두번째 주소를 복사해주시고 curl -X POST -F file=@bichon1.jpg 옆에 빈칸 한번 띄어서 붙여주시면 되시는데\n",
        "                                                                                                          여기서 주의 하실 점은 bichon2.jpg입니다. 이 부분도 사진의 이름에 맞게 바꿔주시면 됩니다. )\n",
        "5. \"C:\\Users\\user\\Pictures\\test2\" > curl -X POST -F file=@bichon3.jpg http://63dd-34-71-213-192.ngrok.io \n",
        "6. \"C:\\Users\\user\\Pictures\\test2\" > curl -X POST -F file=@bichon4.jpg http://63dd-34-71-213-192.ngrok.io \n",
        "7. \"C:\\Users\\user\\Pictures\\test2\" > curl -X POST -F file=@bichon5.jpg http://63dd-34-71-213-192.ngrok.io \n",
        "8. \"C:\\Users\\user\\Pictures\\test2\" > curl -X POST -F file=@bichon6.jpg http://63dd-34-71-213-192.ngrok.io \n",
        "9. \"C:\\Users\\user\\Pictures\\test2\" > curl -X POST -F file=@bichon7.jpg http://63dd-34-71-213-192.ngrok.io \n",
        "10. \"C:\\Users\\user\\Pictures\\test2\" > curl -X POST -F file=@bichon8.jpg http://63dd-34-71-213-192.ngrok.io\n",
        "11. \"C:\\Users\\user\\Pictures\\test2\" > curl -X POST -F file=@bichon9.jpg http://63dd-34-71-213-192.ngrok.io \n",
        "\n",
        "-> \"C:\\Users\\user\\Pictures\\test2\" 대신에 폴더가 있는 경로\n",
        "   http://63dd-34-71-213-192.ngrok.io 대신에 위에 run_with_ngrok(application) application.run()코드를 실행시켜줬을 때 두번째 running on의 주소를 복사\n",
        "   bichon2.jpg 이부분도 사진의 이름에 맞게 바꿔주시면 될 거 같습니다.\n",
        "\"\"\"   "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}